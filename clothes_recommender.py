import dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# from weather_agent import result_weather

dotenv.load_dotenv()


def clothes_recommender(weather):
    """
    ç©¿æ­æ¨è
    :param weather:
    :return:
    """

    llm = ChatOpenAI(
        model = "gpt-4o-mini"
    )

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç©¿æ­é¡¾é—®ï¼Œæ ¹æ®å¤©æ°”ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›åˆé€‚çš„ç©¿æ­å»ºè®®ã€‚

        è¯·æ ¹æ®ä»¥ä¸‹å¤©æ°”ä¿¡æ¯ï¼Œç»™å‡ºè¯¦ç»†ã€å®ç”¨çš„ç©¿æ­æ¨èï¼š
        - è€ƒè™‘æ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿã€å¤©æ°”çŠ¶å†µ
        - æ¨èå…·ä½“çš„æœè£…ç±»å‹å’Œæè´¨
        - ç»™å‡ºæ­é…å»ºè®®å’Œæ³¨æ„äº‹é¡¹
        - è¯­æ°”äº²åˆ‡ä¸“ä¸šã€è¯­è¨€ç®€çŸ­ç²¾ç‚¼

        è¾“å‡ºæ ¼å¼ï¼š
        ğŸ‘• ç©¿æ­æ¨èï¼š
        [å…·ä½“çš„æ¨èå†…å®¹]

        ğŸ’¡ æ¸©é¦¨æç¤ºï¼š
        [æ³¨æ„äº‹é¡¹]"""),
        ("human", "å¤©æ°”ä¿¡æ¯ï¼š\n{weather}")
    ])

    chain = prompt_template | llm

    response = chain.invoke({"weather":weather})
    return response.content



# if __name__ == '__main__':
#     weather = result_weather['output']
#     recommender = clothes_recommender(weather)
#     print(recommender)