import os
import dotenv
import requests
# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.tools import Tool
# from langchain_openai import ChatOpenAI

dotenv.load_dotenv()


def geocode_address(address):
    """
    è·å–èµ·ç‚¹å’Œç»ˆç‚¹çš„ç»çº¬åº¦
    """
    GEOCODE_API_KEY = os.getenv('GEOCODE_API_KEY')
    GEOCODE_BASE_URL = os.getenv('GEOCODE_BASE_URL')
    params = {
        'q': address,
        'api_key': GEOCODE_API_KEY,
    }

    response = requests.get(GEOCODE_BASE_URL, params=params)
    data = response.json()

    if data and len(data) > 0:
        location = f"{data[0]['lon']},{data[0]['lat']}"
        return location
    else:
        return None


def route_planning(route_query):
    """
    ä½¿ç”¨é«˜å¾·APIè¿›è¡Œè·¯å¾„è§„åˆ’
    """
    ROUTE_API_KEY = os.getenv('ROUTE_API_KEY')
    ROUTE_BASE_URL = os.getenv('ROUTE_BASE_URL')

    points = route_query.split(',')
    if len(points) < 2:
        return "è¯·æä¾›èµ·ç‚¹å’Œç»ˆç‚¹ï¼Œæ ¼å¼ï¼šèµ·ç‚¹ï¼Œç»ˆç‚¹"

    start_address = points[0].strip()
    end_address = points[1].strip()

    print(f"æ­£åœ¨æŸ¥è¯¢èµ·ç‚¹ï¼š{start_address}")
    print(f"æ­£åœ¨æŸ¥è¯¢ç»ˆç‚¹ï¼š{end_address}")

    start_location = geocode_address(start_address)
    end_location = geocode_address(end_address)

    print(f"èµ·ç‚¹çš„ç»çº¬åº¦ï¼š{start_location}")
    print(f"ç»ˆç‚¹çš„ç»çº¬åº¦ï¼š{end_location}")

    if not start_location:
        return f"æ— æ³•æ‰¾åˆ°èµ·ç‚¹ '{start_address}' çš„åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"
    if not end_location:
        return f"æ— æ³•æ‰¾åˆ°ç»ˆç‚¹ '{end_address}' çš„åæ ‡ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®"

    params = {
        'key': ROUTE_API_KEY,
        'origin': start_location,
        'destination': end_location,
        'strategy': 0,
        'extensions': 'all',
    }

    print("è°ƒç”¨é«˜å¾·API...")
    response = requests.get(ROUTE_BASE_URL, params=params)
    data = response.json()

    print(f"é«˜å¾·APIå“åº”çŠ¶æ€: {data.get('status')}, ä¿¡æ¯: {data.get('info')}")

    if data['status'] == '1':
        route = data['route']
        path = route['paths'][0]

        # æ„å»ºè¯¦ç»†ç»“æœ
        result = f"ğŸš— è·¯çº¿è§„åˆ’å®Œæˆï¼š{start_address} â†’ {end_address}\n\n"
        result += f"ğŸ“Š æ€»è§ˆï¼š\n"
        result += f"ğŸ“ æ€»è·ç¦»ï¼š{int(path['distance']) / 1000:.1f}å…¬é‡Œ\n"
        result += f"â±ï¸ é¢„è®¡æ—¶é—´ï¼š{int(path['duration']) / 60:.1f}åˆ†é’Ÿ\n"
        result += f"ğŸ—ºï¸ è¯¦ç»†è·¯çº¿ï¼ˆå…±{len(path['steps'])}æ­¥ï¼‰ï¼š\n"

        steps = path['steps']
        for i, step in enumerate(steps, 1):
            instruction = step['instruction']
            instruction = instruction.replace('<b>', '').replace('</b>', '').replace('&nbsp;', ' ')
            distance = f"{int(step['distance']) / 1000:.1f}å…¬é‡Œ" if int(
                step['distance']) >= 1000 else f"{step['distance']}ç±³"

            result += f"{i},{instruction},{distance}\n"

        return result
    else:
        return f"è·¯å¾„è§„åˆ’é”™è¯¯ï¼š{data.get('info', 'æœªçŸ¥é”™è¯¯')}"

#
# route_tools = Tool(
#     func=route_planning,
#     name="route_planning",
#     description="ä½¿ç”¨é«˜å¾·åœ°å›¾è¿›è¡Œé©¾è½¦è·¯å¾„è§„åˆ’"
# )
#
# # è·å–å¤§è¯­è¨€æ¨¡å‹
# llm = ChatOpenAI(model_name="gpt-4o-mini")
#
# # æç¤ºè¯
# prompt_template = ChatPromptTemplate.from_messages([
#     ("system",
#      "ä½ æ˜¯ä¸€ä¸ªè·¯å¾„è§„åˆ’åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§„åˆ’é©¾è½¦è·¯çº¿ã€‚å½“ç”¨æˆ·è¯¢é—®è·¯çº¿æ—¶ï¼Œè°ƒç”¨route_planningå·¥å…·ï¼Œè¾“å…¥æ ¼å¼ä¸ºï¼šèµ·ç‚¹åœ°å€,ç»ˆç‚¹åœ°å€"),
#     ("human", "{input}"),
#     ("placeholder", "{agent_scratchpad}"),
# ])
#
# agent = create_tool_calling_agent(
#     llm=llm,
#     prompt=prompt_template,
#     tools=[route_tools],
# )
#
# memory = ConversationBufferMemory()
#
# agent_executor = AgentExecutor(
#     agent=agent,
#     tools=[route_tools],
#     verbose=True,
#     memory=memory,
# )
#
# user_input = input("è¯·è¾“å…¥ä½ çš„éœ€æ±‚ï¼š")
# result_route = agent_executor.invoke({"input": user_input})
# print(result_route)
